{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from data import data_path\n",
    "from images import images_path\n",
    "from utils.utils_workflow import plot_shapley_function, plot_shapley_value\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scenario_id</th>\n",
       "      <th>type_covariate</th>\n",
       "      <th>type_transformation</th>\n",
       "      <th>eta</th>\n",
       "      <th>sample_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>fourier_expansion</td>\n",
       "      <td>linear_unimodal</td>\n",
       "      <td>0.05</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>fourier_expansion</td>\n",
       "      <td>linear_unimodal</td>\n",
       "      <td>0.05</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>fourier_expansion</td>\n",
       "      <td>linear_unimodal</td>\n",
       "      <td>0.25</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>fourier_expansion</td>\n",
       "      <td>linear_unimodal</td>\n",
       "      <td>0.25</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>fourier_expansion</td>\n",
       "      <td>linear_bimodal</td>\n",
       "      <td>0.05</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   scenario_id     type_covariate type_transformation   eta  sample_size\n",
       "0            1  fourier_expansion     linear_unimodal  0.05          200\n",
       "1            2  fourier_expansion     linear_unimodal  0.05          500\n",
       "2            3  fourier_expansion     linear_unimodal  0.25          200\n",
       "3            4  fourier_expansion     linear_unimodal  0.25          500\n",
       "4            5  fourier_expansion      linear_bimodal  0.05          200"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inupt_path = os.path.join(data_path, \"input\")\n",
    "scenarios_file = os.path.join(inupt_path, \"scenarios_all.csv\")\n",
    "scenarios_df = pd.read_csv(scenarios_file)\n",
    "scenarios_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_keys = [\"intervals\", \"middle_points\"]\n",
    "models = [\"fnn\", \"knn\", \"lm\"]\n",
    "translation_dict = {\n",
    "    \"fnn\": \"fnn\",\n",
    "    \"knn\": \"fknn\",\n",
    "    \"lm\": \"flm\",\n",
    "    \"mRMR_distance_correlation\": \"distance_corr\",\n",
    "    \"mRMR_r2\": \"mRMR\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shapley value and $r^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gather the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data_path = os.path.join(data_path, \"output\")\n",
    "output_data_path_content = os.listdir(output_data_path)\n",
    "scenarios = [x for x in output_data_path_content if 'scenario_' in  x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decide whether to use the same number of simulations for all scenarios.\n",
    "# If use_min_number_of_simulations is True, the minumum number of simulations will be used.\n",
    "# Else if num_sim_to_use is not None, this number will be used\n",
    "# Otherwise all scenarios use all the simulations computed\n",
    "use_min_number_of_simulations = True\n",
    "num_sim_to_use = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of simulations per scenario\n",
    "simulations_data = {}\n",
    "min_num_sim = np.Inf\n",
    "# Iterate throughout all scenarios\n",
    "for current_scenario_name in scenarios:\n",
    "    simulations_data[current_scenario_name] = {}\n",
    "    current_scenario_path = os.path.join(output_data_path, current_scenario_name)\n",
    "    current_scenario_path_content = os.listdir(current_scenario_path)\n",
    "    shapley_files = [x for x in current_scenario_path_content if 'shapley_' in  x]\n",
    "    simulations_identifiers = [x[8:-4] for x in shapley_files]\n",
    "    num_simulations_current_sc = len(shapley_files)\n",
    "    simulations_data[current_scenario_name][\"num_simulations\"] = num_simulations_current_sc\n",
    "    simulations_data[current_scenario_name][\"simulations_ids\"] = simulations_identifiers\n",
    "    if num_simulations_current_sc < min_num_sim:\n",
    "        min_num_sim = num_simulations_current_sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print(min_num_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for current_scenario_name in simulations_data.keys():\n",
    "    simulations_identifiers = simulations_data[current_scenario_name][\"simulations_ids\"]\n",
    "    sim_to_select = len(simulations_identifiers)\n",
    "    if use_min_number_of_simulations:\n",
    "        sim_to_select = min_num_sim\n",
    "    elif not num_sim_to_use is None:\n",
    "        sim_to_select = num_sim_to_use\n",
    "    np.random.seed(1234)\n",
    "    selected_sample = np.random.choice(\n",
    "        a=simulations_identifiers,\n",
    "        size=sim_to_select,\n",
    "        replace=False\n",
    "    )\n",
    "    simulations_data[current_scenario_name][\"selected_simulations_ids\"] = list(selected_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_sanity_check = False\n",
    "# Sanity check\n",
    "if run_sanity_check:\n",
    "    for current_scenario_name in simulations_data.keys():\n",
    "        print(current_scenario_name)\n",
    "        if (use_min_number_of_simulations) or not (num_sim_to_use is None):\n",
    "            print(len(simulations_data[current_scenario_name][\"selected_simulations_ids\"]))\n",
    "        else:\n",
    "            print(len(simulations_data[current_scenario_name][\"selected_simulations_ids\"]) - simulations_data[current_scenario_name][\"num_simulations\"])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"number_simulations.txt\", \"w\") as f:\n",
    "    for i_sim in range(1, 61):\n",
    "        key = f\"scenario_{i_sim}\"\n",
    "        num_s = simulations_data[key][\"num_simulations\"]\n",
    "        sel_sim = len(simulations_data[key][\"selected_simulations_ids\"])\n",
    "        str_line = f\"{key} -> total simulations: {num_s}, selected simulations: {sel_sim}\\n\"\n",
    "        f.write(str_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the data as a dictionary\n",
    "results_shapley_dict = {}\n",
    "results_r2_dict = {}\n",
    "results_distance_corr = {}\n",
    "results_correlation_coeff = {}\n",
    "# Iterate throughout all scenarios\n",
    "for current_scenario_name in scenarios:\n",
    "#for current_scenario_name in [\"scenario_1\"]:\n",
    "    current_scenario_path = os.path.join(output_data_path, current_scenario_name)\n",
    "    selected_simulations_ids = simulations_data[current_scenario_name][\"selected_simulations_ids\"]\n",
    "    shapley_files = [\n",
    "        f\"shapley_{sim}.pkl\" for sim in selected_simulations_ids\n",
    "    ]\n",
    "    # Iterate throughout all Shapley files\n",
    "    for current_shapley_name in shapley_files:\n",
    "        max_val = -np.inf\n",
    "        current_shapley_file = os.path.join(current_scenario_path, current_shapley_name)\n",
    "        with open(current_shapley_file, \"rb\") as file:\n",
    "            data = pickle.load(file)\n",
    "        data_keys = data.keys()\n",
    "        if current_scenario_name in results_shapley_dict.keys():\n",
    "            #print(current_scenario_name, \"key fould\")\n",
    "            for k in data_keys:\n",
    "                current_data = np.array(data[k])\n",
    "                if not k in main_keys:\n",
    "                    current_data_floor = np.maximum(current_data, 0)\n",
    "                    if k == \"mRMR_distance_correlation\":\n",
    "                        sum_values = np.sum(current_data_floor)\n",
    "                        current_data_floor = np.multiply(\n",
    "                            current_data_floor,\n",
    "                            sum_values\n",
    "                        )\n",
    "                    max_current_data_floor = np.max(current_data_floor)\n",
    "                    results_shapley_dict[current_scenario_name][k] = np.row_stack(\n",
    "                        (\n",
    "                            results_shapley_dict[current_scenario_name][k],\n",
    "                            current_data_floor\n",
    "                        )\n",
    "                    )\n",
    "                    if k == \"mRMR_distance_correlation\":\n",
    "                        results_distance_corr[current_scenario_name] = np.row_stack(\n",
    "                            (\n",
    "                                results_distance_corr[current_scenario_name],\n",
    "                                current_data_floor\n",
    "                            )\n",
    "                        )\n",
    "                    if k == \"mRMR_r2\":\n",
    "                        results_correlation_coeff[current_scenario_name] = np.row_stack(\n",
    "                            (\n",
    "                                results_correlation_coeff[current_scenario_name],\n",
    "                                current_data_floor\n",
    "                            )\n",
    "                        )\n",
    "                    if k != \"mRMR_r2\" and max_current_data_floor > max_val:\n",
    "                        #print(k, max_current_data_floor)\n",
    "                        max_val = max_current_data_floor\n",
    "            results_mrmr_r2 = results_shapley_dict[current_scenario_name][\"mRMR_r2\"][-1]\n",
    "            results_shapley_dict[current_scenario_name][\"mRMR_r2\"][-1] = np.multiply(\n",
    "                results_mrmr_r2,\n",
    "                max_val/np.max(results_mrmr_r2)\n",
    "            )\n",
    "        else:\n",
    "            #print(current_scenario_name, \"key not fould\")\n",
    "            results_shapley_dict[current_scenario_name] = {}\n",
    "            for k in data_keys:\n",
    "                current_data = np.array(data[k])\n",
    "                if k in main_keys:\n",
    "                    results_shapley_dict[current_scenario_name][k] = current_data\n",
    "                else:\n",
    "                    current_data_floor = np.maximum(current_data, 0)\n",
    "                    if k == \"mRMR_distance_correlation\":\n",
    "                        sum_values = np.sum(current_data_floor)\n",
    "                        current_data_floor = np.multiply(\n",
    "                            current_data_floor,\n",
    "                            sum_values,\n",
    "                        )\n",
    "                    max_current_data_floor = np.max(current_data_floor)\n",
    "                    results_shapley_dict[current_scenario_name][k] = current_data_floor\n",
    "                    if k == \"mRMR_distance_correlation\":\n",
    "                        results_distance_corr[current_scenario_name] = current_data_floor\n",
    "                    if k == \"mRMR_r2\":\n",
    "                        results_correlation_coeff[current_scenario_name] = current_data_floor\n",
    "                    if k != \"mRMR_r2\" and max_current_data_floor > max_val:\n",
    "                        #print(k, max_current_data_floor)\n",
    "                        max_val = max_current_data_floor\n",
    "            results_mrmr_r2 = results_shapley_dict[current_scenario_name][\"mRMR_r2\"]\n",
    "            results_shapley_dict[current_scenario_name][\"mRMR_r2\"] = np.multiply(\n",
    "                results_mrmr_r2,\n",
    "                max_val/np.max(results_mrmr_r2)\n",
    "            )\n",
    "    # Iterate throughout all r2 files\n",
    "    for current_model in models:\n",
    "        current_r2_model_files = [\n",
    "            f\"r2_test_{current_model}_{sim}.pkl\" for sim in selected_simulations_ids\n",
    "        ]\n",
    "        new_key = translation_dict[current_model]\n",
    "        for current_r2_model_name in current_r2_model_files:\n",
    "            current_r2_file = os.path.join(current_scenario_path, current_r2_model_name)\n",
    "            with open(current_r2_file, \"rb\") as file:\n",
    "                r2_data = pickle.load(file)\n",
    "            if current_scenario_name in results_r2_dict.keys():\n",
    "                if new_key in results_r2_dict[current_scenario_name].keys():\n",
    "                    results_r2_dict[current_scenario_name][new_key].append(r2_data)\n",
    "                else:\n",
    "                    results_r2_dict[current_scenario_name][new_key] = [r2_data]\n",
    "            else:\n",
    "                results_r2_dict[current_scenario_name] = {}\n",
    "                results_r2_dict[current_scenario_name][new_key] = [r2_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute aggregated statistics for the Shapley value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_shapley_dict = {}\n",
    "results_shapley_dict_keys = results_shapley_dict.keys()\n",
    "for sc in results_shapley_dict_keys:\n",
    "    aggregated_shapley_dict[sc] = {}\n",
    "    current_data = results_shapley_dict[sc]\n",
    "    current_data_keys = current_data.keys()\n",
    "    for key in current_data_keys:\n",
    "        if key in main_keys:\n",
    "            aggregated_shapley_dict[sc][key] = current_data[key]\n",
    "        else:\n",
    "            aggregated_shapley_dict[sc][key] = list(np.mean(current_data[key], axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute aggregated statistics for $r^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarios_names = list(results_r2_dict.keys())\n",
    "scenarios_sim = [int(x[9:]) for x in scenarios_names]\n",
    "models_computed = list(results_r2_dict[scenarios_names[0]].keys())\n",
    "stats_to_apply = {\n",
    "    \"mean\" : np.mean,\n",
    "    \"std\" : np.std\n",
    "}\n",
    "stats_to_apply_keys = stats_to_apply.keys()\n",
    "X_r2 = np.full(\n",
    "    shape=(len(scenarios_names), 2*len(models_computed)),\n",
    "    fill_value=np.nan\n",
    ")\n",
    "\n",
    "i_row = 0\n",
    "number_sim = []\n",
    "for sc in scenarios_names:\n",
    "    current_data_sc = results_r2_dict[sc]\n",
    "    current_stats = []\n",
    "    for model in models_computed:\n",
    "        current_data_model = current_data_sc[model]\n",
    "        number_sim.append(len(current_data_model))\n",
    "        for k in stats_to_apply_keys:\n",
    "            fun = stats_to_apply[k]\n",
    "            val = fun(current_data_model)\n",
    "            current_stats.append(val)\n",
    "    X_r2[i_row] = current_stats\n",
    "    i_row += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100\n"
     ]
    }
   ],
   "source": [
    "print(np.min(number_sim), np.max(number_sim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fnn_mean</th>\n",
       "      <th>fnn_std</th>\n",
       "      <th>fknn_mean</th>\n",
       "      <th>fknn_std</th>\n",
       "      <th>flm_mean</th>\n",
       "      <th>flm_std</th>\n",
       "      <th>sim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>scenario_1</th>\n",
       "      <td>0.888671</td>\n",
       "      <td>0.081237</td>\n",
       "      <td>0.539934</td>\n",
       "      <td>0.039190</td>\n",
       "      <td>0.946768</td>\n",
       "      <td>0.005398</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scenario_2</th>\n",
       "      <td>0.928055</td>\n",
       "      <td>0.057306</td>\n",
       "      <td>0.604361</td>\n",
       "      <td>0.027418</td>\n",
       "      <td>0.948764</td>\n",
       "      <td>0.003422</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scenario_3</th>\n",
       "      <td>0.693648</td>\n",
       "      <td>0.056964</td>\n",
       "      <td>0.398740</td>\n",
       "      <td>0.041165</td>\n",
       "      <td>0.731684</td>\n",
       "      <td>0.028210</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scenario_4</th>\n",
       "      <td>0.724672</td>\n",
       "      <td>0.051330</td>\n",
       "      <td>0.458090</td>\n",
       "      <td>0.022135</td>\n",
       "      <td>0.743208</td>\n",
       "      <td>0.018000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scenario_5</th>\n",
       "      <td>0.863417</td>\n",
       "      <td>0.072580</td>\n",
       "      <td>0.537678</td>\n",
       "      <td>0.036970</td>\n",
       "      <td>0.946359</td>\n",
       "      <td>0.006158</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            fnn_mean   fnn_std  fknn_mean  fknn_std  flm_mean   flm_std  sim\n",
       "scenario_1  0.888671  0.081237   0.539934  0.039190  0.946768  0.005398    1\n",
       "scenario_2  0.928055  0.057306   0.604361  0.027418  0.948764  0.003422    2\n",
       "scenario_3  0.693648  0.056964   0.398740  0.041165  0.731684  0.028210    3\n",
       "scenario_4  0.724672  0.051330   0.458090  0.022135  0.743208  0.018000    4\n",
       "scenario_5  0.863417  0.072580   0.537678  0.036970  0.946359  0.006158    5"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_names = []\n",
    "for model in models_computed:\n",
    "    for st in stats_to_apply_keys:\n",
    "        col_names.append(f\"{model}_{st}\")\n",
    "df_r2 = pd.DataFrame(\n",
    "    data=X_r2,\n",
    "    columns=col_names,\n",
    "    index=scenarios_names,\n",
    ")\n",
    "df_r2[\"sim\"] = scenarios_sim\n",
    "df_r2.sort_values(by=\"sim\", inplace=True)\n",
    "df_r2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute aggregated statistics for distance correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_to_apply_keys = stats_to_apply.keys()\n",
    "X_r2_distance_corr = np.full(\n",
    "    shape=(len(scenarios_names), 2),\n",
    "    fill_value=np.nan\n",
    ")\n",
    "\n",
    "i_row = 0\n",
    "number_sim = []\n",
    "for sc in scenarios_names:\n",
    "    current_stats = []\n",
    "    cummulative_distance_corr = np.sum(results_distance_corr[sc], axis=1)\n",
    "    for k in stats_to_apply_keys:\n",
    "        fun = stats_to_apply[k]\n",
    "        val = fun(cummulative_distance_corr)\n",
    "        current_stats.append(val)\n",
    "    X_r2_distance_corr[i_row] = current_stats\n",
    "    i_row += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance_corr_mean</th>\n",
       "      <th>distance_corr_std</th>\n",
       "      <th>sim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>scenario_1</th>\n",
       "      <td>0.234575</td>\n",
       "      <td>0.017557</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scenario_2</th>\n",
       "      <td>0.256436</td>\n",
       "      <td>0.035967</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scenario_3</th>\n",
       "      <td>0.191341</td>\n",
       "      <td>0.015393</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scenario_4</th>\n",
       "      <td>0.187416</td>\n",
       "      <td>0.012467</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scenario_5</th>\n",
       "      <td>0.229060</td>\n",
       "      <td>0.018401</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            distance_corr_mean  distance_corr_std  sim\n",
       "scenario_1            0.234575           0.017557    1\n",
       "scenario_2            0.256436           0.035967    2\n",
       "scenario_3            0.191341           0.015393    3\n",
       "scenario_4            0.187416           0.012467    4\n",
       "scenario_5            0.229060           0.018401    5"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_names = []\n",
    "key_for_distance_correlation = translation_dict[\"mRMR_distance_correlation\"]\n",
    "for k in stats_to_apply.keys():\n",
    "    col_names.append(f\"{key_for_distance_correlation}_{k}\")\n",
    "df_distance_corr = pd.DataFrame(\n",
    "    data=X_r2_distance_corr,\n",
    "    columns=col_names,\n",
    "    index=scenarios_names,\n",
    ")\n",
    "df_distance_corr[\"sim\"] = scenarios_sim\n",
    "df_distance_corr.sort_values(by=\"sim\", inplace=True)\n",
    "df_distance_corr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute aggregated statistics for correlation coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_to_apply_keys = stats_to_apply.keys()\n",
    "X_r2_correlation_coeff = np.full(\n",
    "    shape=(len(scenarios_names), 2),\n",
    "    fill_value=np.nan\n",
    ")\n",
    "\n",
    "i_row = 0\n",
    "number_sim = []\n",
    "for sc in scenarios_names:\n",
    "    current_stats = []\n",
    "    cummulative_correlation_coeff = np.sum(results_correlation_coeff[sc], axis=1)\n",
    "    for k in stats_to_apply_keys:\n",
    "        fun = stats_to_apply[k]\n",
    "        val = fun(cummulative_correlation_coeff)\n",
    "        current_stats.append(val)\n",
    "    X_r2_correlation_coeff[i_row] = current_stats\n",
    "    i_row += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mRMR_mean</th>\n",
       "      <th>mRMR_std</th>\n",
       "      <th>sim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>scenario_1</th>\n",
       "      <td>1.142526</td>\n",
       "      <td>0.065224</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scenario_2</th>\n",
       "      <td>1.153317</td>\n",
       "      <td>0.076267</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scenario_3</th>\n",
       "      <td>1.054376</td>\n",
       "      <td>0.074761</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scenario_4</th>\n",
       "      <td>1.031436</td>\n",
       "      <td>0.043005</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scenario_5</th>\n",
       "      <td>1.342749</td>\n",
       "      <td>0.073404</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            mRMR_mean  mRMR_std  sim\n",
       "scenario_1   1.142526  0.065224    1\n",
       "scenario_2   1.153317  0.076267    2\n",
       "scenario_3   1.054376  0.074761    3\n",
       "scenario_4   1.031436  0.043005    4\n",
       "scenario_5   1.342749  0.073404    5"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_names = []\n",
    "key_for_correlation_coeff = translation_dict[\"mRMR_r2\"]\n",
    "for k in stats_to_apply.keys():\n",
    "    col_names.append(f\"{key_for_correlation_coeff}_{k}\")\n",
    "df_correlation_coeff = pd.DataFrame(\n",
    "    data=X_r2_correlation_coeff,\n",
    "    columns=col_names,\n",
    "    index=scenarios_names,\n",
    ")\n",
    "df_correlation_coeff[\"sim\"] = scenarios_sim\n",
    "df_correlation_coeff.sort_values(by=\"sim\", inplace=True)\n",
    "df_correlation_coeff.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Join all the info regarding $r^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarios_df_reindex = scenarios_df.set_index(\"scenario_id\")\n",
    "df_r2_reindex = df_r2.set_index(\"sim\")\n",
    "df_distance_corr_reindex = df_distance_corr.set_index(\"sim\")\n",
    "df_correlation_coeff_reindex = df_correlation_coeff.set_index(\"sim\")\n",
    "df_r2_results = scenarios_df_reindex.join(df_r2_reindex).join(df_distance_corr_reindex).join(df_correlation_coeff_reindex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type_covariate</th>\n",
       "      <th>type_transformation</th>\n",
       "      <th>eta</th>\n",
       "      <th>sample_size</th>\n",
       "      <th>fnn_mean</th>\n",
       "      <th>fnn_std</th>\n",
       "      <th>fknn_mean</th>\n",
       "      <th>fknn_std</th>\n",
       "      <th>flm_mean</th>\n",
       "      <th>flm_std</th>\n",
       "      <th>distance_corr_mean</th>\n",
       "      <th>distance_corr_std</th>\n",
       "      <th>mRMR_mean</th>\n",
       "      <th>mRMR_std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scenario_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fourier_expansion</td>\n",
       "      <td>linear_unimodal</td>\n",
       "      <td>0.05</td>\n",
       "      <td>200</td>\n",
       "      <td>0.888671</td>\n",
       "      <td>0.081237</td>\n",
       "      <td>0.539934</td>\n",
       "      <td>0.039190</td>\n",
       "      <td>0.946768</td>\n",
       "      <td>0.005398</td>\n",
       "      <td>0.234575</td>\n",
       "      <td>0.017557</td>\n",
       "      <td>1.142526</td>\n",
       "      <td>0.065224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fourier_expansion</td>\n",
       "      <td>linear_unimodal</td>\n",
       "      <td>0.05</td>\n",
       "      <td>500</td>\n",
       "      <td>0.928055</td>\n",
       "      <td>0.057306</td>\n",
       "      <td>0.604361</td>\n",
       "      <td>0.027418</td>\n",
       "      <td>0.948764</td>\n",
       "      <td>0.003422</td>\n",
       "      <td>0.256436</td>\n",
       "      <td>0.035967</td>\n",
       "      <td>1.153317</td>\n",
       "      <td>0.076267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fourier_expansion</td>\n",
       "      <td>linear_unimodal</td>\n",
       "      <td>0.25</td>\n",
       "      <td>200</td>\n",
       "      <td>0.693648</td>\n",
       "      <td>0.056964</td>\n",
       "      <td>0.398740</td>\n",
       "      <td>0.041165</td>\n",
       "      <td>0.731684</td>\n",
       "      <td>0.028210</td>\n",
       "      <td>0.191341</td>\n",
       "      <td>0.015393</td>\n",
       "      <td>1.054376</td>\n",
       "      <td>0.074761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fourier_expansion</td>\n",
       "      <td>linear_unimodal</td>\n",
       "      <td>0.25</td>\n",
       "      <td>500</td>\n",
       "      <td>0.724672</td>\n",
       "      <td>0.051330</td>\n",
       "      <td>0.458090</td>\n",
       "      <td>0.022135</td>\n",
       "      <td>0.743208</td>\n",
       "      <td>0.018000</td>\n",
       "      <td>0.187416</td>\n",
       "      <td>0.012467</td>\n",
       "      <td>1.031436</td>\n",
       "      <td>0.043005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fourier_expansion</td>\n",
       "      <td>linear_bimodal</td>\n",
       "      <td>0.05</td>\n",
       "      <td>200</td>\n",
       "      <td>0.863417</td>\n",
       "      <td>0.072580</td>\n",
       "      <td>0.537678</td>\n",
       "      <td>0.036970</td>\n",
       "      <td>0.946359</td>\n",
       "      <td>0.006158</td>\n",
       "      <td>0.229060</td>\n",
       "      <td>0.018401</td>\n",
       "      <td>1.342749</td>\n",
       "      <td>0.073404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>fourier_expansion</td>\n",
       "      <td>linear_bimodal</td>\n",
       "      <td>0.05</td>\n",
       "      <td>500</td>\n",
       "      <td>0.896299</td>\n",
       "      <td>0.091714</td>\n",
       "      <td>0.604633</td>\n",
       "      <td>0.020266</td>\n",
       "      <td>0.948560</td>\n",
       "      <td>0.003144</td>\n",
       "      <td>0.248430</td>\n",
       "      <td>0.028364</td>\n",
       "      <td>1.407653</td>\n",
       "      <td>0.077145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>fourier_expansion</td>\n",
       "      <td>linear_bimodal</td>\n",
       "      <td>0.25</td>\n",
       "      <td>200</td>\n",
       "      <td>0.654205</td>\n",
       "      <td>0.071994</td>\n",
       "      <td>0.399486</td>\n",
       "      <td>0.039844</td>\n",
       "      <td>0.731468</td>\n",
       "      <td>0.027795</td>\n",
       "      <td>0.187650</td>\n",
       "      <td>0.013758</td>\n",
       "      <td>1.221481</td>\n",
       "      <td>0.074737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fourier_expansion</td>\n",
       "      <td>linear_bimodal</td>\n",
       "      <td>0.25</td>\n",
       "      <td>500</td>\n",
       "      <td>0.697895</td>\n",
       "      <td>0.063745</td>\n",
       "      <td>0.461300</td>\n",
       "      <td>0.025181</td>\n",
       "      <td>0.741472</td>\n",
       "      <td>0.018525</td>\n",
       "      <td>0.183911</td>\n",
       "      <td>0.013359</td>\n",
       "      <td>1.257244</td>\n",
       "      <td>0.053093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fourier_expansion</td>\n",
       "      <td>non_linear_unimodal</td>\n",
       "      <td>0.05</td>\n",
       "      <td>200</td>\n",
       "      <td>0.336131</td>\n",
       "      <td>0.144991</td>\n",
       "      <td>0.048966</td>\n",
       "      <td>0.080440</td>\n",
       "      <td>-0.028925</td>\n",
       "      <td>0.033138</td>\n",
       "      <td>0.092482</td>\n",
       "      <td>0.006675</td>\n",
       "      <td>0.542551</td>\n",
       "      <td>0.068400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>fourier_expansion</td>\n",
       "      <td>non_linear_unimodal</td>\n",
       "      <td>0.05</td>\n",
       "      <td>500</td>\n",
       "      <td>0.526594</td>\n",
       "      <td>0.097789</td>\n",
       "      <td>0.110786</td>\n",
       "      <td>0.043696</td>\n",
       "      <td>-0.011125</td>\n",
       "      <td>0.011346</td>\n",
       "      <td>0.060870</td>\n",
       "      <td>0.005502</td>\n",
       "      <td>0.419796</td>\n",
       "      <td>0.054551</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                type_covariate  type_transformation   eta  sample_size  \\\n",
       "scenario_id                                                              \n",
       "1            fourier_expansion      linear_unimodal  0.05          200   \n",
       "2            fourier_expansion      linear_unimodal  0.05          500   \n",
       "3            fourier_expansion      linear_unimodal  0.25          200   \n",
       "4            fourier_expansion      linear_unimodal  0.25          500   \n",
       "5            fourier_expansion       linear_bimodal  0.05          200   \n",
       "6            fourier_expansion       linear_bimodal  0.05          500   \n",
       "7            fourier_expansion       linear_bimodal  0.25          200   \n",
       "8            fourier_expansion       linear_bimodal  0.25          500   \n",
       "9            fourier_expansion  non_linear_unimodal  0.05          200   \n",
       "10           fourier_expansion  non_linear_unimodal  0.05          500   \n",
       "\n",
       "             fnn_mean   fnn_std  fknn_mean  fknn_std  flm_mean   flm_std  \\\n",
       "scenario_id                                                                \n",
       "1            0.888671  0.081237   0.539934  0.039190  0.946768  0.005398   \n",
       "2            0.928055  0.057306   0.604361  0.027418  0.948764  0.003422   \n",
       "3            0.693648  0.056964   0.398740  0.041165  0.731684  0.028210   \n",
       "4            0.724672  0.051330   0.458090  0.022135  0.743208  0.018000   \n",
       "5            0.863417  0.072580   0.537678  0.036970  0.946359  0.006158   \n",
       "6            0.896299  0.091714   0.604633  0.020266  0.948560  0.003144   \n",
       "7            0.654205  0.071994   0.399486  0.039844  0.731468  0.027795   \n",
       "8            0.697895  0.063745   0.461300  0.025181  0.741472  0.018525   \n",
       "9            0.336131  0.144991   0.048966  0.080440 -0.028925  0.033138   \n",
       "10           0.526594  0.097789   0.110786  0.043696 -0.011125  0.011346   \n",
       "\n",
       "             distance_corr_mean  distance_corr_std  mRMR_mean  mRMR_std  \n",
       "scenario_id                                                              \n",
       "1                      0.234575           0.017557   1.142526  0.065224  \n",
       "2                      0.256436           0.035967   1.153317  0.076267  \n",
       "3                      0.191341           0.015393   1.054376  0.074761  \n",
       "4                      0.187416           0.012467   1.031436  0.043005  \n",
       "5                      0.229060           0.018401   1.342749  0.073404  \n",
       "6                      0.248430           0.028364   1.407653  0.077145  \n",
       "7                      0.187650           0.013758   1.221481  0.074737  \n",
       "8                      0.183911           0.013359   1.257244  0.053093  \n",
       "9                      0.092482           0.006675   0.542551  0.068400  \n",
       "10                     0.060870           0.005502   0.419796  0.054551  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_r2_results.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_r2_results.to_csv(os.path.join(data_path, \"other\", \"r2_models.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots for the Shapley value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_shapley_dict_keys = list(aggregated_shapley_dict.keys())\n",
    "for scenario in aggregated_shapley_dict_keys:\n",
    "    current_scenario_id_int = int(scenario[9:])\n",
    "    current_scenario_id_str = str(current_scenario_id_int)\n",
    "    current_scenario_id_str = current_scenario_id_str.zfill(2)\n",
    "    val = aggregated_shapley_dict[scenario]\n",
    "    current_scenario_info = scenarios_df[scenarios_df[\"scenario_id\"] == current_scenario_id_int]\n",
    "    current_eta = str(current_scenario_info.eta.squeeze()).replace(\".\", \"\")\n",
    "    file_name = f\"{current_scenario_id_str}__{current_scenario_info.type_covariate.squeeze()}__{current_scenario_info.type_transformation.squeeze()}__{current_scenario_info.sample_size.squeeze()}__{current_eta}.pdf\"\n",
    "    lgd = plot_shapley_value(\n",
    "        obj=val,\n",
    "        domain_range=(0, 1),\n",
    "        translation_dict=translation_dict,\n",
    "        display_legend=False,\n",
    "    )\n",
    "    plt.savefig(os.path.join(images_path, file_name), format=\"pdf\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_shapley_dict_keys = list(aggregated_shapley_dict.keys())\n",
    "for scenario in aggregated_shapley_dict_keys:\n",
    "    current_scenario_id_int = int(scenario[9:])\n",
    "    current_scenario_id_str = str(current_scenario_id_int)\n",
    "    current_scenario_id_str = current_scenario_id_str.zfill(2)\n",
    "    val = aggregated_shapley_dict[scenario]\n",
    "    current_scenario_info = scenarios_df[scenarios_df[\"scenario_id\"] == current_scenario_id_int]\n",
    "    current_eta = str(current_scenario_info.eta.squeeze()).replace(\".\", \"\")\n",
    "    file_name = f\"step_{current_scenario_id_str}__{current_scenario_info.type_covariate.squeeze()}__{current_scenario_info.type_transformation.squeeze()}__{current_scenario_info.sample_size.squeeze()}__{current_eta}.pdf\"\n",
    "    plot_shapley_function(obj=val, domain_range=(0, 1), translation_dict=translation_dict)\n",
    "    plt.savefig(os.path.join(images_path, file_name), format=\"pdf\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_to_consider = ['intervals', 'middle_points', 'lm']\n",
    "val = aggregated_shapley_dict[\"scenario_1\"]\n",
    "single_scenario = {k: val[k] for k in keys_to_consider} \n",
    "plot_shapley_value(\n",
    "    obj=single_scenario,\n",
    "    domain_range=(0, 1),\n",
    "    display_legend=False,\n",
    "    translation_dict=translation_dict,\n",
    ")\n",
    "plt.savefig(os.path.join(images_path, \"shapley_relevance_single_scenario.pdf\"), format=\"pdf\")\n",
    "plt.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_shapley_function(\n",
    "    obj=single_scenario,\n",
    "    domain_range=(0, 1),\n",
    "    plot_h_line=True,\n",
    "    plot_v_line=True,\n",
    "    display_legend=False,\n",
    ")\n",
    "plt.savefig(os.path.join(images_path, \"shapley_step_single_scenario.pdf\"), format=\"pdf\")\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Legend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.colors import ListedColormap\n",
    "colors_code = np.array([\n",
    "    [255, 0, 0],\n",
    "    [0, 255, 0],\n",
    "    [0, 0, 255],\n",
    "    [0, 0, 0],\n",
    "    [218, 112, 214],\n",
    "    [107, 223, 205],\n",
    "    [128, 128, 128]\n",
    "])/255\n",
    "cmap = ListedColormap(colors_code)\n",
    "colors = cmap.colors\n",
    "function_names = [\n",
    "    translation_dict[x] for x in aggregated_shapley_dict[\"scenario_1\"].keys() if x not in main_keys\n",
    "]\n",
    "leg = plt.legend(\n",
    "    handles=[Line2D([], [], color=col, lw=2.5) for col in colors],\n",
    "    labels=function_names,\n",
    "    loc='upper center',\n",
    "    bbox_to_anchor=(0.5, -0.05),\n",
    "    fancybox=True,\n",
    "    shadow=True,\n",
    "    ncol=len(function_names),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig  = leg.figure\n",
    "fig.canvas.draw()\n",
    "bbox  = leg.get_window_extent().transformed(fig.dpi_scale_trans.inverted())\n",
    "fig.savefig(os.path.join(images_path, \"my_legend.pdf\"), dpi=\"figure\", bbox_inches=bbox, format=\"pdf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".shapley_fda_experiments",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
