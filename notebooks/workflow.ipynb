{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from data import data_path\n",
    "from hyperopt.fnn import HyperOptFnn\n",
    "from shapley.shapley_fda import ShapleyFda\n",
    "from skfda.ml.regression import LinearRegression\n",
    "from skfda.representation.basis import BSplineBasis\n",
    "from skfda.representation.grid import FDataGrid\n",
    "from utils.predict_np import predict_from_np\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_csv_files(files):\n",
    "    unique_numbers = []\n",
    "    csv_files = [x.split(\".\")[0] for x in files if \"csv\" in x.split(\".\")]\n",
    "    all_numbers = [int(x.split(\"_\")[-1]) for x in csv_files]\n",
    "    for x in all_numbers:\n",
    "        if not x in unique_numbers:\n",
    "            unique_numbers.append(x)\n",
    "    return len(unique_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(i_sim, path):\n",
    "    type_data = [\"train\", \"validation\", \"test\"]\n",
    "    X_str = \"X_sim_{}_{}.csv\"\n",
    "    target_str = \"target_sim_{}_{}.csv\"\n",
    "    X = [\n",
    "            pd.read_csv(os.path.join(path, X_str.format(x, i_sim))) for x in type_data\n",
    "        ]\n",
    "    target = [\n",
    "            pd.read_csv(os.path.join(path, target_str.format(x, i_sim))) for x in type_data\n",
    "        ]\n",
    "    \n",
    "    colnames = X[0].columns.values\n",
    "    all_data = [*X, *target]\n",
    "    all_data_numpy = [x.to_numpy() for x in all_data]\n",
    "    return [colnames, *all_data_numpy]\n",
    "\n",
    "def get_abscissa_points(names):\n",
    "    points = [float(c.split(\"_\")[1]) for c in names]\n",
    "    return np.array(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_no_verbose(predict_fn):\n",
    "    def inner(*args, **kwargs):\n",
    "        return predict_fn(*args, verbose=False, **kwargs)\n",
    "    return inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_range = (0, 1)\n",
    "num_intervals = 20\n",
    "num_permutations = 50\n",
    "simulated_data_path = os.path.join(data_path, \"output\")\n",
    "scenario_path = \"scenario_5\"\n",
    "full_path = os.path.join(simulated_data_path, scenario_path)\n",
    "all_files = os.listdir(full_path)\n",
    "n_basis_representation = 20\n",
    "basis_bsplines = BSplineBasis(\n",
    "    n_basis=n_basis_representation,\n",
    "    domain_range=domain_range\n",
    ")\n",
    "i_sim = 0\n",
    "colnames, X_train, X_val, X_test, target_train, target_val, target_test = read_data(i_sim, full_path)\n",
    "X_full = np.row_stack((X_train, X_val))\n",
    "target_full = np.row_stack((target_train, target_val))\n",
    "abscissa_points = get_abscissa_points(colnames)\n",
    "X_full_grid = FDataGrid(\n",
    "    data_matrix=X_full,\n",
    "    grid_points=abscissa_points,\n",
    "    domain_range=domain_range\n",
    ")\n",
    "X_full_bspline = X_full_grid.to_basis(basis_bsplines)\n",
    "### Perform hyperopt for neural networks\n",
    "hyper_opt_fnn = HyperOptFnn(\n",
    "    input_shape=(X_train.shape[1], 1),\n",
    "    resolution=X_train.shape[1]\n",
    ")\n",
    "tuner_fnn = hyper_opt_fnn.build_tuner(\n",
    "    objective=\"val_loss\",\n",
    "    max_trials=3,\n",
    "    overwrite=True,\n",
    "    directory=\".\",\n",
    "    project_name=\"tune_hypermodel\",\n",
    ")\n",
    "tuner_fnn.search(X_train, target_train, epochs=2, validation_data=(X_val, target_val), verbose=False)\n",
    "# Use the best model\n",
    "best_hp_fnn = tuner_fnn.get_best_hyperparameters()[0]\n",
    "hypermodel_final = HyperOptFnn(\n",
    "    input_shape=(X_train.shape[1], 1),\n",
    "    resolution=X_train.shape[1]\n",
    ")\n",
    "model_fnn = hypermodel_final.build(best_hp_fnn)\n",
    "history = hypermodel_final.fit(\n",
    "    best_hp_fnn,\n",
    "    model_fnn,\n",
    "    X_full,\n",
    "    target_full,\n",
    "    verbose=False,\n",
    "    epochs=1,\n",
    ")\n",
    "### Perform hyperopt for linear model\n",
    "linear_reg = LinearRegression()\n",
    "_ = linear_reg.fit(X_full_bspline, target_full[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Compute relevance for neural network\n",
    "shapley_fda_fnn = ShapleyFda(\n",
    "    predict_fn=predict_no_verbose(model_fnn.predict),\n",
    "    X=X_test,\n",
    "    abscissa_points=abscissa_points,\n",
    "    target=target_test[:, 0],\n",
    "    domain_range=domain_range,\n",
    "    verbose=False,\n",
    ")\n",
    "values_shapley_fnn = shapley_fda_fnn.compute_shapley_value(\n",
    "    num_intervals=num_intervals,\n",
    "    num_permutations=num_permutations,\n",
    ")\n",
    "shapley_fda_fnn.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Compute relevance for linear model\n",
    "num_permutations = 100\n",
    "# Transform predict function to use a numpy array as input\n",
    "pred_lm = predict_from_np(\n",
    "    grid_points=abscissa_points,\n",
    "    domain_range=domain_range,\n",
    "    basis=X_full_bspline.basis,\n",
    "    predict_fn=linear_reg.predict\n",
    ")\n",
    "\n",
    "shapley_fda_lm = ShapleyFda(\n",
    "    predict_fn=pred_lm,\n",
    "    X=X_test,\n",
    "    abscissa_points=abscissa_points,\n",
    "    target=target_test,\n",
    "    domain_range=domain_range,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "values_shapley_lm = shapley_fda_lm.compute_shapley_value(\n",
    "    num_intervals=num_intervals,\n",
    "    num_permutations=num_permutations,\n",
    ")\n",
    "shapley_fda_lm.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_lm(X_test) - target_test[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Perform hyperopt for linear model\n",
    "linear_reg = LinearRegression()\n",
    "_ = linear_reg.fit(X_full_bspline, target_full[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_reg.predict(X_full_bspline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_range = (0, 1)\n",
    "num_intervals = 20\n",
    "num_permutations = 10\n",
    "simulated_data_path = os.path.join(data_path, \"output\")\n",
    "for scenario_path in os.listdir(simulated_data_path):\n",
    "    full_path = os.path.join(simulated_data_path, scenario_path)\n",
    "    all_files = os.listdir(full_path)\n",
    "    n_simulation = count_csv_files(all_files)\n",
    "    for i_sim in range(n_simulation):\n",
    "        # Read the data\n",
    "        print(scenario_path, i_sim)\n",
    "        colnames, X_train, X_val, X_test, target_train, target_val, target_test = read_data(i_sim, full_path)\n",
    "        abscissa_points = get_abscissa_points(colnames)\n",
    "        # Perform hyperopt for neural networks\n",
    "        hyper_opt_fnn = HyperOptFnn(\n",
    "            input_shape=(X_train.shape[1], 1),\n",
    "            resolution=X_train.shape[1]\n",
    "        )\n",
    "        tuner = hyper_opt_fnn.build_tuner(\n",
    "            objective=\"val_loss\",\n",
    "            max_trials=3,\n",
    "            overwrite=True,\n",
    "            directory=\".\",\n",
    "            project_name=\"tune_hypermodel\",\n",
    "        )\n",
    "        tuner.search(X_train, target_train, epochs=2, validation_data=(X_val, target_val))\n",
    "        # Use the best model\n",
    "        best_hp = tuner.get_best_hyperparameters()[0]\n",
    "        hypermodel_final = HyperOptFnn(\n",
    "            input_shape=(X_train.shape[1], 1),\n",
    "            resolution=X_train.shape[1]\n",
    "        )\n",
    "        model = hypermodel_final.build(best_hp)\n",
    "        hypermodel_final.fit(\n",
    "            best_hp,\n",
    "            model,\n",
    "            np.row_stack((X_train, X_val)),\n",
    "            np.row_stack((target_train, target_val)),\n",
    "            epochs=1\n",
    "        )\n",
    "        # Compute relevance\n",
    "        shapley_fda_fnn = ShapleyFda(\n",
    "            predict_fn=model.predict,\n",
    "            X=X_test,\n",
    "            abscissa_points=abscissa_points,\n",
    "            target=target_test,\n",
    "            domain_range=domain_range,\n",
    "            verbose=False,\n",
    "        )\n",
    "        values_shapley_fnn = shapley_fda_fnn.compute_shapley_value(\n",
    "            num_intervals=num_intervals,\n",
    "            num_permutations=num_permutations,\n",
    "        )\n",
    "        # Store the results\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".shapley_fda_experiments",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
