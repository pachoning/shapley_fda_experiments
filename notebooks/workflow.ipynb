{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from data import data_path\n",
    "from hyperopt.fnn import HyperOptFnn\n",
    "from hyperopt.sklearn_gridsearch import HyperOptScikitFda\n",
    "from shapley.shapley_fda import ShapleyFda\n",
    "from skfda.misc.operators import LinearDifferentialOperator\n",
    "from skfda.misc.regularization import L2Regularization\n",
    "from skfda.ml.regression import KNeighborsRegressor, LinearRegression\n",
    "from skfda.representation.basis import BSplineBasis\n",
    "from skfda.representation.grid import FDataGrid\n",
    "from utils.predict_np import predict_from_np\n",
    "from utils.config import num_simulations\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(i_sim, path):\n",
    "    type_data = [\"train\", \"validation\", \"test\"]\n",
    "    X_str = \"X_sim_{}_{}.csv\"\n",
    "    target_str = \"target_sim_{}_{}.csv\"\n",
    "    X = [\n",
    "            pd.read_csv(os.path.join(path, X_str.format(x, i_sim))) for x in type_data\n",
    "        ]\n",
    "    target = [\n",
    "            pd.read_csv(os.path.join(path, target_str.format(x, i_sim))) for x in type_data\n",
    "        ]\n",
    "    \n",
    "    colnames = X[0].columns.values\n",
    "    all_data = [*X, *target]\n",
    "    all_data_numpy = [x.to_numpy() for x in all_data]\n",
    "    return [colnames, *all_data_numpy]\n",
    "\n",
    "def get_abscissa_points(names):\n",
    "    points = [float(c.split(\"_\")[1]) for c in names]\n",
    "    return np.array(points)\n",
    "\n",
    "def predict_no_verbose(predict_fn):\n",
    "    def inner(*args, **kwargs):\n",
    "        return predict_fn(*args, verbose=False, **kwargs)\n",
    "    return inner\n",
    "\n",
    "def l2_reg(lambda_value):\n",
    "    operator = L2Regularization(\n",
    "        linear_operator=LinearDifferentialOperator(2),\n",
    "        regularization_parameter=lambda_value\n",
    "    )\n",
    "    return operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_range = (0, 1)\n",
    "num_intervals = 20\n",
    "num_permutations = 10\n",
    "simulated_data_path = os.path.join(data_path, \"output\")\n",
    "n_basis_representation = 10\n",
    "basis_bsplines = BSplineBasis(\n",
    "    n_basis=n_basis_representation,\n",
    "    domain_range=(0 ,1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_list = [l2_reg(x) for x in np.arange(0.2, 1.5, 0.2)]\n",
    "reg_list.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_intervals = 20\n",
    "num_permutations = 10\n",
    "get_lm_results = True\n",
    "get_knn_results = True\n",
    "get_fnn_results = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 6 Complete [00h 00m 03s]\n",
      "val_loss: 7.149473822209984e-05\n",
      "\n",
      "Best val_loss So Far: 7.137554348446429e-05\n",
      "Total elapsed time: 00h 00m 20s\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 7.4938e-05   \n"
     ]
    }
   ],
   "source": [
    "for i_sim in range(num_simulations):\n",
    "    for scenario_path in os.listdir(simulated_data_path):\n",
    "        full_path = os.path.join(simulated_data_path, scenario_path)\n",
    "        all_files = os.listdir(full_path)\n",
    "        # Read the data\n",
    "        print(scenario_path, i_sim)\n",
    "        colnames, X_train, X_validation, X_test, target_train, target_validation, target_test = read_data(i_sim, full_path)\n",
    "        abscissa_points = get_abscissa_points(colnames)\n",
    "        X_full = np.row_stack((X_train, X_validation))\n",
    "        target_full = np.row_stack((target_train, target_validation))\n",
    "        # Transform the data\n",
    "        X_train_grid = FDataGrid(\n",
    "            data_matrix=X_train,\n",
    "            grid_points=abscissa_points,\n",
    "        )\n",
    "        X_validation_grid = FDataGrid(\n",
    "            data_matrix=X_validation,\n",
    "            grid_points=abscissa_points,\n",
    "        )\n",
    "        X_test_grid = FDataGrid(\n",
    "            data_matrix=X_test,\n",
    "            grid_points=abscissa_points,\n",
    "        )\n",
    "        X_full_grid = FDataGrid(\n",
    "            data_matrix=X_full,\n",
    "            grid_points=abscissa_points,\n",
    "        )\n",
    "        X_train_bspline = X_train_grid.to_basis(basis_bsplines)\n",
    "        X_validation_bspline = X_validation_grid.to_basis(basis_bsplines)\n",
    "        X_test_bspline = X_test_grid.to_basis(basis_bsplines)\n",
    "        X_full_bspline = X_full_grid.to_basis(basis_bsplines)\n",
    "        ########## Linear model\n",
    "        if get_lm_results:\n",
    "            hyperopt_lm = HyperOptScikitFda(\n",
    "                LinearRegression,\n",
    "                abscissa_points=abscissa_points,\n",
    "                domain_range=domain_range,\n",
    "            )\n",
    "            params_lm = {\n",
    "                \"regularization\": reg_list\n",
    "            }\n",
    "            hist_lm = hyperopt_lm.search(\n",
    "                params=params_lm,\n",
    "                X_train=X_train_bspline,\n",
    "                y_train=target_train[:, 0],\n",
    "                X_val=X_validation_bspline,\n",
    "                y_val=target_validation[:, 0]\n",
    "            )\n",
    "            best_params_lm = hist_lm.best_params_\n",
    "            best_model_lm = hyperopt_lm.cls_estimator(**best_params_lm)\n",
    "            _ = best_model_lm.fit(X_full_bspline, target_full[:, 0])\n",
    "            # Transform predict function to use a numpy array as input\n",
    "            pred_lm = predict_from_np(\n",
    "                grid_points=abscissa_points,\n",
    "                domain_range=domain_range,\n",
    "                basis=X_full_bspline.basis,\n",
    "                predict_fn=best_model_lm.predict\n",
    "            )\n",
    "            # Shapley for the Linear Model\n",
    "            shapley_fda_lm = ShapleyFda(\n",
    "                predict_fn=pred_lm,\n",
    "                X=X_test,\n",
    "                abscissa_points=abscissa_points,\n",
    "                target=target_test[:, 0],\n",
    "                domain_range=domain_range,\n",
    "                verbose=False,\n",
    "            )\n",
    "            values_shapley_lm = shapley_fda_lm.compute_shapley_value(\n",
    "                num_intervals=num_intervals,\n",
    "                num_permutations=num_permutations,\n",
    "            )\n",
    "            values_shapley_lm_name = f\"shapley_lm_{i_sim}.pkl\"\n",
    "            values_shapley_lm_file = os.path.join(data_path, \"output\", scenario_path, values_shapley_lm_name)\n",
    "            with open(values_shapley_lm_file, 'wb') as f_lm:\n",
    "                    pickle.dump(values_shapley_lm, f_lm)\n",
    "        ########## KNN\n",
    "        if get_knn_results:\n",
    "            hyperopt_knn = HyperOptScikitFda(\n",
    "                KNeighborsRegressor,\n",
    "                abscissa_points=abscissa_points,\n",
    "                domain_range=domain_range,\n",
    "            )\n",
    "            hist_knn = hyperopt_knn.search(\n",
    "                params={\"n_neighbors\": range(3, 12, 2)},\n",
    "                X_train=X_train,\n",
    "                y_train=target_train,\n",
    "                X_val=X_validation,\n",
    "                y_val=target_validation\n",
    "            )\n",
    "            best_params_knn = hist_knn.best_params_\n",
    "            best_model_knn = hyperopt_knn.cls_estimator(**best_params_knn)\n",
    "            _ = best_model_knn.fit(X_full, target_full)\n",
    "            # Shapley for the KNN\n",
    "            shapley_fda_knn = ShapleyFda(\n",
    "                predict_fn=best_model_knn.predict,\n",
    "                X=X_test,\n",
    "                abscissa_points=abscissa_points,\n",
    "                target=target_test,\n",
    "                domain_range=domain_range,\n",
    "                verbose=False,\n",
    "            )\n",
    "            values_shapley_knn = shapley_fda_knn.compute_shapley_value(\n",
    "                num_intervals=num_intervals,\n",
    "                num_permutations=num_permutations,\n",
    "            )\n",
    "            values_shapley_knn_name = f\"shapley_knn_{i_sim}.pkl\"\n",
    "            values_shapley_knn_file = os.path.join(data_path, \"output\", scenario_path, values_shapley_knn_name)\n",
    "            with open(values_shapley_knn_file, 'wb') as f_knn:\n",
    "                pickle.dump(values_shapley_knn, f_knn)\n",
    "        \n",
    "        ########## FNN\n",
    "        if get_fnn_results: \n",
    "            hyperopt_fnn = HyperOptFnn(\n",
    "                input_shape=(X_train.shape[1], 1),\n",
    "                resolution=X_train.shape[1]\n",
    "            )\n",
    "\n",
    "            tuner_fnn = hyperopt_fnn.build_tuner(\n",
    "                objective=\"val_loss\",\n",
    "                max_trials=12,\n",
    "                overwrite=True,\n",
    "                directory=\".\",\n",
    "                project_name=\"tune_hypermodel\",\n",
    "            )\n",
    "\n",
    "            tuner_fnn.search(\n",
    "                X_train,\n",
    "                target_train,\n",
    "                epochs=10,\n",
    "                batch_size=32,\n",
    "                validation_data=(X_validation, target_validation)\n",
    "            )\n",
    "\n",
    "            best_model_fnn = HyperOptFnn(\n",
    "                input_shape=(X_train.shape[1], 1),\n",
    "                resolution=X_train.shape[1]\n",
    "            )\n",
    "\n",
    "            best_params_fnn = tuner_fnn.get_best_hyperparameters(5)[0]\n",
    "            model_fnn = best_model_fnn.build(best_params_fnn)\n",
    "            history = best_model_fnn.fit(best_params_fnn, model_fnn, X_full, target_full, batch_size=32, epochs=1)\n",
    "            # Shapley for FNN\n",
    "            shapley_fda_fnn = ShapleyFda(\n",
    "                predict_fn=predict_no_verbose(model_fnn.predict),\n",
    "                X=X_test,\n",
    "                abscissa_points=abscissa_points,\n",
    "                target=target_test,\n",
    "                domain_range=domain_range,\n",
    "                verbose=False,\n",
    "            )\n",
    "\n",
    "            values_shapley_fnn = shapley_fda_fnn.compute_shapley_value(\n",
    "                num_intervals=num_intervals,\n",
    "                num_permutations=num_permutations,\n",
    "            )\n",
    "            values_shapley_fnn_name = f\"shapley_fnn_{i_sim}.pkl\"\n",
    "            values_shapley_fnn_file = os.path.join(data_path, \"output\", scenario_path, values_shapley_fnn_name)\n",
    "            with open(values_shapley_fnn_file, 'wb') as f_knn:\n",
    "                pickle.dump(values_shapley_fnn, f_knn)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
